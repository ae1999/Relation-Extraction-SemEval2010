{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "military-broad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "generic-beauty",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelationNet(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, vocab_size, class_size, num_layers):\n",
    "        super(RelationNet, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "        W = torch.randn((vocab_size, embed_size), requires_grad=True)\n",
    "        self.embed.weight = nn.Parameter(W)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, bidirectional = True, batch_first = True)\n",
    "        self.linear = nn.Linear(4*hidden_size, class_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        self.dropout = nn.Dropout(0.35)\n",
    "        \n",
    "    def forward(self, sentence):\n",
    "        embeddings = self.embed(sentence)\n",
    "        hiddens, _ = self.lstm(self.dropout(embeddings))\n",
    "#         lstm_out = torch.cat((hiddens[:, :, 149], hiddens[:, :, 299]), dim = 1)\n",
    "        lstm_out = torch.cat((hiddens[:, 0, :], hiddens[:, -1, :]), dim = 1)\n",
    "        outputs = self.linear(lstm_out)\n",
    "        outputs = self.softmax(outputs)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quarterly-identification",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelationNet_glove(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, vocab_size, class_size, num_layers):\n",
    "        super(RelationNet_glove, self).__init__()\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, bidirectional = True, batch_first = True)\n",
    "        self.linear = nn.Linear(hidden_size*4, class_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        self.dropout = nn.Dropout(0.35)\n",
    "        \n",
    "    def forward(self, sentence):\n",
    "        hiddens, _ = self.lstm(self.dropout(sentence))\n",
    "        lstm_out = torch.cat((hiddens[:, 0, :], hiddens[:, -1, :]), dim = 1)\n",
    "        outputs = self.linear(lstm_out)\n",
    "        outputs = self.softmax(outputs)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informative-brave",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelationNet_glove_indexed(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, vocab_size, class_size, num_layers):\n",
    "        super(RelationNet_glove_indexed, self).__init__()\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, bidirectional = True, batch_first = True)\n",
    "        self.linear = nn.Linear(hidden_size*2, class_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        self.dropout = nn.Dropout(0.35)\n",
    "        \n",
    "    def forward(self, sentence_index):\n",
    "        sentence, index = sentence_index[0], sentence_index[1]\n",
    "        inds = torch.round(index.float().mean(0))\n",
    "        hiddens, _ = self.lstm(self.dropout(sentence))\n",
    "        output_forward, output_backward = torch.chunk(hiddens, 2, 2)\n",
    "        lstm_out = torch.cat((output_forward.unsqueeze(2),output_backward.unsqueeze(2)), dim=2)\n",
    "        lstm_out, b = torch.max(lstm_out, 2)\n",
    "        lstm_out = torch.cat((lstm_out[:, int(inds[0]), :], lstm_out[:, int(inds[1]), :]), dim = 1)\n",
    "        outputs = self.linear(lstm_out)\n",
    "        outputs = self.softmax(outputs)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottom-abraham",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, filename=\"my_checkpoint.pth.tar\"):\n",
    "    print(\"=> Saving checkpoint\")\n",
    "    torch.save(state, filename)\n",
    "\n",
    "def load_checkpoint(checkpoint, model, optimizer):\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "    step = checkpoint[\"step\"]\n",
    "    return modelstep"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_x86",
   "language": "python",
   "name": "pytorch_x86"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
